{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "- Input with `.csv` files, which start with `relingo` and output `.txt` files with specific formats:\n",
    "  - The `.csv`'s columns include 'word', 'translation','phonetic','mastered','sentences'.\n",
    "  - Remove the 'mastered' column, keep other columns, and rearrange the content in the csv into format like:\n",
    "  ```\n",
    "    *word1 \n",
    "    **phonetic1 \n",
    "    ====================================\n",
    "    1. translation1.1\n",
    "    2. translation1.2\n",
    "    3. translation1.3\n",
    "    ...\n",
    "    x. translation1.x\n",
    "    ====================================\n",
    "    1. sentences1.1\n",
    "    2. sentences1.2\n",
    "    ...\n",
    "    y. sentences1.y\n",
    "\n",
    "    *word2 \n",
    "    **phonetic2 \n",
    "    ====================================\n",
    "    translation2 \n",
    "    ...\n",
    "    ====================================\n",
    "    sentences2\n",
    "    ...\n",
    "\n",
    "    ...... \n",
    "\n",
    "    *wordn \n",
    "    **phoneticn \n",
    "    ====================================\n",
    "    translationn\n",
    "    ...\n",
    "    ====================================\n",
    "    sentencesn\n",
    "    ...\n",
    "  ```\n",
    "  - If the `translation`'s content has multiple rows, only keep the first row of it. And if the 'translation' and 'sentences' have multiple of them, which could be divided by ';', then split them into different rows and add corresponding serial number.\n",
    "- Select out newly added words\n",
    "  - The `.csv` would contain old words, create `added_words.txt` to compare with each time, select only 'word' column's content to save in after selecting out those new words to `new_words.txt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def process_csv(file_path, added_words_file='added_words.txt'):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Remove the 'mastered' column and rearrange the columns\n",
    "    df = df.drop(columns=['mastered'])\n",
    "    df = df[['word', 'translation', 'phonetic', 'sentences']]\n",
    "\n",
    "     # Only keep the first row of the 'translation' content if it has multiple rows\n",
    "    df['translation'] = df['translation'].apply(lambda x: x.split('\\n')[0] if isinstance(x, str) else x)\n",
    "\n",
    "    # Function to rearrange 'translation' content\n",
    "    # Function to rearrange 'translation' content\n",
    "    def rearrange_translation(text):\n",
    "        if isinstance(text, str):\n",
    "            # Use a regular expression to match word classes and split accordingly\n",
    "            parts = re.split(r'((?:NOUN|VERB|ADJ|ADV)\\.)', text)\n",
    "            result = []\n",
    "            count = 1  # Initialize count\n",
    "            \n",
    "            for i in range(len(parts)):\n",
    "                part = parts[i].strip()\n",
    "                if not part:\n",
    "                    continue\n",
    "                # If the part is a word class, add it without numbering\n",
    "                if re.match(r'^(NOUN|VERB|ADJ|ADV)\\.$', part):\n",
    "                    result.append(part)  # Add the word class as a new line\n",
    "                    count = 1  # Reset numbering for a new word class\n",
    "                else:\n",
    "                    # Split the following content on delimiters and add numbering\n",
    "                    sub_parts = re.split(r'[；;，]', part)\n",
    "                    for sub_part in sub_parts:\n",
    "                        result.append(f\"{count}. {sub_part.strip()}\")\n",
    "                        count += 1\n",
    "                        \n",
    "            return '\\n'.join(result)\n",
    "        return text\n",
    "    \n",
    "    df['translation'] = df['translation'].apply(rearrange_translation)\n",
    "    \n",
    "    # Split 'sentences' on ';' and add serial numbers\n",
    "    def split_and_number(text):\n",
    "        if isinstance(text, str):\n",
    "            parts = text.split(';')\n",
    "            return '\\n'.join([f\"{i+1}. {part.strip()}\" for i, part in enumerate(parts)])\n",
    "        return text\n",
    "    \n",
    "    df['sentences'] = df['sentences'].apply(split_and_number)\n",
    "    \n",
    "    # Check if the added_words.txt exists\n",
    "    if os.path.exists(added_words_file):\n",
    "        with open(added_words_file, 'r', encoding='utf-8') as f:\n",
    "            old_words = f.read().splitlines()\n",
    "    else:\n",
    "        old_words = []\n",
    "    \n",
    "    # Find new words\n",
    "    new_words_df = df[~df['word'].isin(old_words)]\n",
    "    \n",
    "    # Prepare the output format for new words\n",
    "    output_lines = []\n",
    "    for _, row in new_words_df.iterrows():\n",
    "        # Convert each value to string and handle missing values by replacing NaN with an empty string\n",
    "        word = str(row['word']) if not pd.isna(row['word']) else \"\"\n",
    "        phonetic = str(row['phonetic']) if not pd.isna(row['phonetic']) else \"\"\n",
    "        translation = str(row['translation']) if not pd.isna(row['translation']) else \"\"\n",
    "        sentences = str(row['sentences']) if not pd.isna(row['sentences']) else \"\"\n",
    "\n",
    "        # Append the formatted strings to output_lines\n",
    "        output_lines.append(f\"*{word}\")\n",
    "        output_lines.append(f\"**{phonetic}\")\n",
    "        output_lines.append(\"==================\")\n",
    "        output_lines.append(translation)\n",
    "        output_lines.append(\"==================\")\n",
    "        output_lines.append(sentences)\n",
    "        output_lines.append(\"\\n\")\n",
    "        \n",
    "    # Save the new words' data to new_words.txt\n",
    "    if output_lines:\n",
    "        with open('new_words.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(output_lines))\n",
    "        print(\"New words found and formatted data saved to new_words.txt\")\n",
    "    \n",
    "    # Append the new words to added_words.txt\n",
    "    with open(added_words_file, 'a', encoding='utf-8') as f:\n",
    "        for word in new_words_df['word']:\n",
    "            f.write(f\"{word}\\n\")\n",
    "    \n",
    "    print(f\"Updated {added_words_file} with the latest words.\")\n",
    "    \n",
    "\n",
    "# Example of how to use the function\n",
    "input_directory = '.'  # Change to your directory\n",
    "\n",
    "for file_name in os.listdir(input_directory):\n",
    "    if file_name.startswith('relingo') and file_name.endswith('.csv'):\n",
    "        process_csv(os.path.join(input_directory, file_name))\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
